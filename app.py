import streamlit as st
import torch
from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor
from PIL import Image
import io
import base64
import re
from config import DEVICE, USE_GPU, GENERATION_CONFIG, PROMPTS

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="Uni-MuMER-Qwen2.5-VL-7B Demo",
    page_icon="üßÆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS t√πy ch·ªânh
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        text-align: center;
        margin-bottom: 2rem;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    .result-box {
        background-color: #f8f9fa;
        border: 2px solid #e9ecef;
        border-radius: 10px;
        padding: 20px;
        margin: 20px 0;
    }
    .latex-preview {
        background-color: white;
        border: 1px solid #ddd;
        border-radius: 5px;
        padding: 15px;
        margin: 10px 0;
        text-align: center;
    }
    .upload-section {
        border: 2px dashed #007bff;
        border-radius: 10px;
        padding: 30px;
        text-align: center;
        background-color: #f8f9ff;
    }
    .sidebar .sidebar-content {
        background-color: #f8f9fa;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_resource
def load_model():
    """Load m√¥ h√¨nh v√† tokenizer"""
    try:
        # Load m√¥ h√¨nh t·ª´ th∆∞ m·ª•c local
        from config import MODEL_PATH, MODEL_CONFIG
        
        # Load processor v√† tokenizer
        processor = AutoProcessor.from_pretrained(MODEL_PATH, trust_remote_code=True)
        tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)
        
        # Load m√¥ h√¨nh v·ªõi c·∫•u h√¨nh t·ªëi ∆∞u
        model = Qwen2VLForConditionalGeneration.from_pretrained(
            MODEL_PATH,
            **MODEL_CONFIG
        )
        
        return model, processor, tokenizer
    except Exception as e:
        st.error(f"L·ªói khi load m√¥ h√¨nh: {str(e)}")
        return None, None, None

def process_image_to_latex(image, model, processor, tokenizer):
    """Chuy·ªÉn ƒë·ªïi ·∫£nh th√†nh LaTeX"""
    try:
        # Chu·∫©n b·ªã prompt cho to√°n h·ªçc
        prompt = PROMPTS["math_to_latex"]
        
        # X·ª≠ l√Ω ·∫£nh v√† text
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": image},
                    {"type": "text", "text": prompt}
                ]
            }
        ]
        
        # Tokenize
        text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
        image_inputs, video_inputs = processor.process_vision_info(messages)
        inputs = processor(text=[text], images=image_inputs, videos=video_inputs, return_tensors="pt")
        
        # Generate v·ªõi c·∫•u h√¨nh t·ªëi ∆∞u
        with torch.no_grad():
            generated_ids = model.generate(
                **inputs,
                **GENERATION_CONFIG
            )
        
        # Decode
        generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, generated_ids)]
        response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
        
        # L√†m s·∫°ch output ƒë·ªÉ ch·ªâ l·∫•y LaTeX
        latex_code = clean_latex_output(response)
        
        return latex_code
        
    except Exception as e:
        st.error(f"L·ªói khi x·ª≠ l√Ω ·∫£nh: {str(e)}")
        return None

def clean_latex_output(text):
    """L√†m s·∫°ch output ƒë·ªÉ ch·ªâ l·∫•y LaTeX code"""
    # Lo·∫°i b·ªè c√°c t·ª´ kh√≥a kh√¥ng c·∫ßn thi·∫øt
    text = re.sub(r'^(LaTeX|latex|Latex):?\s*', '', text, flags=re.IGNORECASE)
    text = re.sub(r'^(Here is|The|This is).*?:\s*', '', text, flags=re.IGNORECASE)
    
    # T√¨m v√† tr√≠ch xu·∫•t LaTeX code trong d·∫•u $$
    latex_match = re.search(r'\$\$(.*?)\$\$', text, re.DOTALL)
    if latex_match:
        return latex_match.group(1).strip()
    
    # T√¨m LaTeX code trong d·∫•u $
    latex_match = re.search(r'\$(.*?)\$', text, re.DOTALL)
    if latex_match:
        return latex_match.group(1).strip()
    
    # N·∫øu kh√¥ng t√¨m th·∫•y d·∫•u $, tr·∫£ v·ªÅ text ƒë√£ l√†m s·∫°ch
    return text.strip()

def render_latex(latex_code):
    """Render LaTeX code th√†nh c√¥ng th·ª©c to√°n h·ªçc"""
    try:
        # S·ª≠ d·ª•ng st.latex ƒë·ªÉ render
        st.latex(latex_code)
        return True
    except Exception as e:
        st.warning(f"Kh√¥ng th·ªÉ render LaTeX: {str(e)}")
        return False

def main():
    # Header
    st.markdown('<h1 class="main-header">üßÆ Uni-MuMER-Qwen2.5-VL-7B Demo</h1>', unsafe_allow_html=True)
    st.markdown("### Chuy·ªÉn ƒë·ªïi ·∫£nh to√°n h·ªçc th√†nh LaTeX")
    
    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è C√†i ƒë·∫∑t")
        
        # Model settings
        st.subheader("Th√¥ng s·ªë m√¥ h√¨nh")
        max_tokens = st.slider("Max tokens", 100, 1000, 512)
        temperature = st.slider("Temperature", 0.0, 1.0, 0.1)
        
        # Instructions
        st.subheader("üìñ H∆∞·ªõng d·∫´n")
        st.markdown("""
        1. **Upload ·∫£nh**: Ch·ªçn file ·∫£nh ch·ª©a c√¥ng th·ª©c to√°n h·ªçc
        2. **X·ª≠ l√Ω**: Nh·∫•n n√∫t "Chuy·ªÉn ƒë·ªïi" ƒë·ªÉ ch·∫°y m√¥ h√¨nh
        3. **K·∫øt qu·∫£**: Xem LaTeX code v√† c√¥ng th·ª©c ƒë∆∞·ª£c render
        4. **Copy**: Sao ch√©p LaTeX code ƒë·ªÉ s·ª≠ d·ª•ng
        """)
        
        # Supported formats
        st.subheader("üìÅ ƒê·ªãnh d·∫°ng h·ªó tr·ª£")
        st.markdown("""
        - **PNG** (.png)
        - **JPEG** (.jpg, .jpeg)
        - **BMP** (.bmp)
        - **TIFF** (.tiff)
        """)
    
    # Main content
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("üì§ Upload ·∫£nh")
        
        # Upload file
        uploaded_file = st.file_uploader(
            "Ch·ªçn file ·∫£nh ch·ª©a c√¥ng th·ª©c to√°n h·ªçc",
            type=['png', 'jpg', 'jpeg', 'bmp', 'tiff'],
            help="Upload ·∫£nh ch·ª©a c√¥ng th·ª©c to√°n h·ªçc ƒë·ªÉ chuy·ªÉn ƒë·ªïi th√†nh LaTeX"
        )
        
        if uploaded_file is not None:
            # Hi·ªÉn th·ªã ·∫£nh
            image = Image.open(uploaded_file)
            st.image(image, caption="·∫¢nh ƒë√£ upload", use_column_width=True)
            
            # Th√¥ng tin file
            st.info(f"üìÅ **File**: {uploaded_file.name}  \nüìè **K√≠ch th∆∞·ªõc**: {image.size}")
    
    with col2:
        st.subheader("‚ö° X·ª≠ l√Ω")
        
        if uploaded_file is not None:
            # Load model
            with st.spinner("üîÑ ƒêang load m√¥ h√¨nh..."):
                model, processor, tokenizer = load_model()
            
            if model is not None:
                # Process button
                if st.button("üöÄ Chuy·ªÉn ƒë·ªïi sang LaTeX", type="primary", use_container_width=True):
                    with st.spinner("üîÑ ƒêang x·ª≠ l√Ω ·∫£nh..."):
                        latex_result = process_image_to_latex(image, model, processor, tokenizer)
                    
                    if latex_result:
                        st.success("‚úÖ Chuy·ªÉn ƒë·ªïi th√†nh c√¥ng!")
                        
                        # Display results
                        st.markdown('<div class="result-box">', unsafe_allow_html=True)
                        st.subheader("üìù LaTeX Code:")
                        
                        # LaTeX code
                        st.code(latex_result, language="latex")
                        
                        # Copy button
                        if st.button("üìã Copy LaTeX Code", use_container_width=True):
                            st.code(latex_result)
                            st.success("‚úÖ ƒê√£ copy v√†o clipboard!")
                        
                        st.markdown("</div>", unsafe_allow_html=True)
                        
                        # Preview
                        st.subheader("üëÅÔ∏è Preview:")
                        st.markdown('<div class="latex-preview">', unsafe_allow_html=True)
                        if render_latex(latex_result):
                            st.success("‚úÖ Render th√†nh c√¥ng!")
                        else:
                            st.warning("‚ö†Ô∏è Kh√¥ng th·ªÉ render LaTeX")
                        st.markdown('</div>', unsafe_allow_html=True)
                    else:
                        st.error("‚ùå Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi ·∫£nh")
            else:
                st.error("‚ùå Kh√¥ng th·ªÉ load m√¥ h√¨nh. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n m√¥ h√¨nh.")
        else:
            st.info("üëÜ Vui l√≤ng upload ·∫£nh ƒë·ªÉ b·∫Øt ƒë·∫ßu")
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666;'>
        <p>üöÄ <strong>Uni-MuMER-Qwen2.5-VL-7B</strong> - Chuy·ªÉn ƒë·ªïi ·∫£nh to√°n h·ªçc th√†nh LaTeX</p>
        <p>üí° D·ª±a tr√™n m√¥ h√¨nh Qwen2.5-VL-7B-Instruct</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
