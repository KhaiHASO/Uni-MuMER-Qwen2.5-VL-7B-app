# ğŸ§® Uni-MuMER-Qwen2.5-VL-7B Streamlit Demo

á»¨ng dá»¥ng Streamlit Ä‘á»ƒ demo mÃ´ hÃ¬nh **Uni-MuMER-Qwen2.5-VL-7B** - chuyá»ƒn Ä‘á»•i áº£nh toÃ¡n há»c thÃ nh LaTeX code.

## ğŸ“‹ MÃ´ táº£

Uni-MuMER-Qwen2.5-VL-7B lÃ  má»™t mÃ´ hÃ¬nh Vision-Language Ä‘Æ°á»£c fine-tune tá»« Qwen2.5-VL-7B-Instruct, chuyÃªn dá»¥ng Ä‘á»ƒ chuyá»ƒn Ä‘á»•i áº£nh chá»©a cÃ´ng thá»©c toÃ¡n há»c thÃ nh mÃ£ LaTeX. á»¨ng dá»¥ng nÃ y cung cáº¥p giao diá»‡n web thÃ¢n thiá»‡n Ä‘á»ƒ demo kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh.

## âœ¨ TÃ­nh nÄƒng

- ğŸ–¼ï¸ **Upload áº£nh**: Há»— trá»£ nhiá»u Ä‘á»‹nh dáº¡ng áº£nh (PNG, JPEG, BMP, TIFF)
- ğŸ”„ **Chuyá»ƒn Ä‘á»•i tá»± Ä‘á»™ng**: Chuyá»ƒn Ä‘á»•i áº£nh toÃ¡n há»c thÃ nh LaTeX code
- ğŸ‘ï¸ **Preview**: Xem trÆ°á»›c cÃ´ng thá»©c Ä‘Æ°á»£c render
- ğŸ“‹ **Copy code**: Sao chÃ©p LaTeX code Ä‘á»ƒ sá»­ dá»¥ng
- âš™ï¸ **TÃ¹y chá»‰nh**: Äiá»u chá»‰nh cÃ¡c tham sá»‘ mÃ´ hÃ¬nh
- ğŸ“± **Responsive**: Giao diá»‡n thÃ¢n thiá»‡n trÃªn má»i thiáº¿t bá»‹

## ğŸš€ CÃ i Ä‘áº·t

### YÃªu cáº§u há»‡ thá»‘ng

- **Python**: 3.10+
- **CUDA**: 11.8+ (khuyáº¿n nghá»‹ cho GPU)
- **RAM**: Tá»‘i thiá»ƒu 16GB (khuyáº¿n nghá»‹ 32GB+)
- **VRAM**: Tá»‘i thiá»ƒu 8GB (náº¿u sá»­ dá»¥ng GPU)

### CÃ i Ä‘áº·t báº±ng Conda (Khuyáº¿n nghá»‹)

1. **Clone repository**:
```bash
git clone <repository-url>
cd uni-mumer-qwen2.5-vl-streamlit
```

2. **Táº¡o mÃ´i trÆ°á»ng conda**:
```bash
conda env create -f environment.yml
```

3. **KÃ­ch hoáº¡t mÃ´i trÆ°á»ng**:
```bash
conda activate uni-mumer-qwen2.5-vl
```

4. **Kiá»ƒm tra cÃ i Ä‘áº·t**:
```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}')"
```

### CÃ i Ä‘áº·t báº±ng pip

1. **Táº¡o mÃ´i trÆ°á»ng Python**:
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# hoáº·c
venv\Scripts\activate     # Windows
```

2. **CÃ i Ä‘áº·t dependencies**:
```bash
pip install -r requirements.txt
```

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
uni-mumer-qwen2.5-vl-streamlit/
â”œâ”€â”€ app.py                 # á»¨ng dá»¥ng Streamlit chÃ­nh
â”œâ”€â”€ model_loader.py        # Module load mÃ´ hÃ¬nh
â”œâ”€â”€ requirements.txt       # Dependencies cho pip
â”œâ”€â”€ environment.yml        # Environment cho conda
â”œâ”€â”€ README.md             # HÆ°á»›ng dáº«n nÃ y
â””â”€â”€ Uni-MuMER-Qwen2.5-VL-7B/  # ThÆ° má»¥c chá»©a mÃ´ hÃ¬nh
    â”œâ”€â”€ config.json
    â”œâ”€â”€ model.safetensors.index.json
    â”œâ”€â”€ tokenizer.json
    â””â”€â”€ ... (cÃ¡c file mÃ´ hÃ¬nh khÃ¡c)
```

## ğŸ¯ Sá»­ dá»¥ng

### Cháº¡y á»©ng dá»¥ng

```bash
streamlit run app.py
```

á»¨ng dá»¥ng sáº½ má»Ÿ táº¡i: `http://localhost:8501`

### HÆ°á»›ng dáº«n sá»­ dá»¥ng

1. **Upload áº£nh**: 
   - Nháº¥n "Browse files" Ä‘á»ƒ chá»n áº£nh chá»©a cÃ´ng thá»©c toÃ¡n há»c
   - Há»— trá»£ Ä‘á»‹nh dáº¡ng: PNG, JPEG, BMP, TIFF

2. **Chuyá»ƒn Ä‘á»•i**:
   - Nháº¥n nÃºt "ğŸš€ Chuyá»ƒn Ä‘á»•i sang LaTeX"
   - Chá» mÃ´ hÃ¬nh xá»­ lÃ½ (cÃ³ thá»ƒ máº¥t vÃ i giÃ¢y)

3. **Xem káº¿t quáº£**:
   - LaTeX code sáº½ hiá»ƒn thá»‹ trong Ã´ káº¿t quáº£
   - Preview cÃ´ng thá»©c Ä‘Æ°á»£c render bÃªn dÆ°á»›i
   - Sá»­ dá»¥ng nÃºt "ğŸ“‹ Copy LaTeX Code" Ä‘á»ƒ sao chÃ©p

4. **TÃ¹y chá»‰nh**:
   - Äiá»u chá»‰nh cÃ¡c tham sá»‘ trong sidebar
   - Max tokens, Temperature, Top-p, etc.

### Sá»­ dá»¥ng module trá»±c tiáº¿p

```python
from model_loader import UniMuMERModel

# Khá»Ÿi táº¡o mÃ´ hÃ¬nh
model = UniMuMERModel("./Uni-MuMER-Qwen2.5-VL-7B")

# Load mÃ´ hÃ¬nh
if model.load_model():
    # Chuyá»ƒn Ä‘á»•i áº£nh
    latex_code = model.convert_image_to_latex("path/to/image.png")
    print(f"LaTeX: {latex_code}")
```

## âš™ï¸ Cáº¥u hÃ¬nh

### Tham sá»‘ mÃ´ hÃ¬nh

- **Max tokens**: Sá»‘ token tá»‘i Ä‘a Ä‘á»ƒ generate (máº·c Ä‘á»‹nh: 512)
- **Temperature**: Nhiá»‡t Ä‘á»™ sampling (máº·c Ä‘á»‹nh: 0.1)
- **Top-p**: Top-p sampling (máº·c Ä‘á»‹nh: 0.9)
- **Repetition penalty**: Penalty cho repetition (máº·c Ä‘á»‹nh: 1.1)

### Cáº¥u hÃ¬nh GPU

MÃ´ hÃ¬nh sáº½ tá»± Ä‘á»™ng sá»­ dá»¥ng GPU náº¿u cÃ³ sáºµn. Äá»ƒ kiá»ƒm tra:

```python
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"GPU count: {torch.cuda.device_count()}")
```

## ğŸ”§ Troubleshooting

### Lá»—i thÆ°á»ng gáº·p

1. **"KhÃ´ng thá»ƒ load mÃ´ hÃ¬nh"**:
   - Kiá»ƒm tra Ä‘Æ°á»ng dáº«n thÆ° má»¥c mÃ´ hÃ¬nh
   - Äáº£m báº£o cÃ³ Ä‘á»§ RAM/VRAM
   - Kiá»ƒm tra cÃ¡c file mÃ´ hÃ¬nh cÃ³ Ä‘áº§y Ä‘á»§ khÃ´ng

2. **"CUDA out of memory"**:
   - Giáº£m batch size
   - Sá»­ dá»¥ng CPU thay vÃ¬ GPU
   - Giáº£m Ä‘á»™ phÃ¢n giáº£i áº£nh

3. **"Module not found"**:
   - CÃ i Ä‘áº·t láº¡i dependencies: `pip install -r requirements.txt`
   - Kiá»ƒm tra mÃ´i trÆ°á»ng conda Ä‘Ã£ Ä‘Æ°á»£c kÃ­ch hoáº¡t

### Performance Tips

- **GPU**: Sá»­ dá»¥ng GPU Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ xá»­ lÃ½
- **RAM**: Äáº£m báº£o cÃ³ Ä‘á»§ RAM (16GB+)
- **áº¢nh**: Sá»­ dá»¥ng áº£nh cÃ³ Ä‘á»™ phÃ¢n giáº£i vá»«a pháº£i
- **Batch**: Xá»­ lÃ½ tá»«ng áº£nh má»™t Ä‘á»ƒ trÃ¡nh out of memory

## ğŸ“Š ThÃ´ng tin mÃ´ hÃ¬nh

- **Base model**: Qwen2.5-VL-7B-Instruct
- **Architecture**: Qwen2_5_VLForConditionalGeneration
- **Parameters**: ~7B
- **Input**: áº¢nh + Text prompt
- **Output**: LaTeX code
- **License**: Apache 2.0

## ğŸ¤ ÄÃ³ng gÃ³p

Má»i Ä‘Ã³ng gÃ³p Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n! Vui lÃ²ng:

1. Fork repository
2. Táº¡o feature branch
3. Commit changes
4. Push to branch
5. Táº¡o Pull Request

## ğŸ“„ License

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¢n phá»‘i dÆ°á»›i giáº¥y phÃ©p Apache 2.0. Xem file `LICENSE` Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.

## ğŸ™ Acknowledgments

- **Qwen Team**: Cho mÃ´ hÃ¬nh Qwen2.5-VL-7B-Instruct
- **Hugging Face**: Cho thÆ° viá»‡n Transformers
- **Streamlit**: Cho framework web app

## ğŸ“ LiÃªn há»‡

Náº¿u cÃ³ cÃ¢u há»i hoáº·c gáº·p váº¥n Ä‘á», vui lÃ²ng táº¡o issue trÃªn GitHub repository.

---

**LÆ°u Ã½**: MÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c fine-tune cho má»¥c Ä‘Ã­ch chuyá»ƒn Ä‘á»•i áº£nh toÃ¡n há»c thÃ nh LaTeX. Káº¿t quáº£ cÃ³ thá»ƒ khÃ¡c nhau tÃ¹y thuá»™c vÃ o cháº¥t lÆ°á»£ng vÃ  Ä‘á»™ phá»©c táº¡p cá»§a áº£nh Ä‘áº§u vÃ o.